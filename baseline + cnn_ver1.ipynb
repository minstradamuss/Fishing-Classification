{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taM7grXVSh1D",
        "outputId": "9473e421-ec08-4ce1-9b7c-9d5a6e77b91a",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/normal/\n",
            "  inflating: data/normal/1.jpg       \n",
            "  inflating: data/normal/10.jpg      \n",
            "  inflating: data/normal/100.jpg     \n",
            "  inflating: data/normal/11.jpg      \n",
            "  inflating: data/normal/12.jpg      \n",
            "  inflating: data/normal/13.jpg      \n",
            "  inflating: data/normal/14.jpg      \n",
            "  inflating: data/normal/15.jpg      \n",
            "  inflating: data/normal/16.jpg      \n",
            "  inflating: data/normal/17.jpg      \n",
            "  inflating: data/normal/18.jpg      \n",
            "  inflating: data/normal/19.jpg      \n",
            "  inflating: data/normal/2.jpg       \n",
            "  inflating: data/normal/20.jpg      \n",
            "  inflating: data/normal/21.jpg      \n",
            "  inflating: data/normal/22.jpg      \n",
            "  inflating: data/normal/23.jpg      \n",
            "  inflating: data/normal/24.jpg      \n",
            "  inflating: data/normal/25.jpg      \n",
            "  inflating: data/normal/26.jpg      \n",
            "  inflating: data/normal/27.jpg      \n",
            "  inflating: data/normal/28.jpg      \n",
            "  inflating: data/normal/29.jpg      \n",
            "  inflating: data/normal/3.jpg       \n",
            "  inflating: data/normal/34.jpg      \n",
            "  inflating: data/normal/35.jpg      \n",
            "  inflating: data/normal/36.jpg      \n",
            "  inflating: data/normal/37.jpg      \n",
            "  inflating: data/normal/38.jpg      \n",
            "  inflating: data/normal/39.jpg      \n",
            "  inflating: data/normal/4.jpg       \n",
            "  inflating: data/normal/40.jpg      \n",
            "  inflating: data/normal/41.jpg      \n",
            "  inflating: data/normal/42.jpg      \n",
            "  inflating: data/normal/43.jpg      \n",
            "  inflating: data/normal/44.jpg      \n",
            "  inflating: data/normal/45.jpg      \n",
            "  inflating: data/normal/46.jpg      \n",
            "  inflating: data/normal/47.jpg      \n",
            "  inflating: data/normal/48.jpg      \n",
            "  inflating: data/normal/49.jpg      \n",
            "  inflating: data/normal/5.jpg       \n",
            "  inflating: data/normal/50.jpg      \n",
            "  inflating: data/normal/51.jpg      \n",
            "  inflating: data/normal/52.jpg      \n",
            "  inflating: data/normal/53.jpg      \n",
            "  inflating: data/normal/54.jpg      \n",
            "  inflating: data/normal/55.jpg      \n",
            "  inflating: data/normal/56.jpg      \n",
            "  inflating: data/normal/57.jpg      \n",
            "  inflating: data/normal/58.jpg      \n",
            "  inflating: data/normal/59.jpg      \n",
            "  inflating: data/normal/6.jpg       \n",
            "  inflating: data/normal/60.jpg      \n",
            "  inflating: data/normal/61.jpg      \n",
            "  inflating: data/normal/62.jpg      \n",
            "  inflating: data/normal/63.jpg      \n",
            "  inflating: data/normal/64.jpg      \n",
            "  inflating: data/normal/65.jpg      \n",
            "  inflating: data/normal/66.jpg      \n",
            "  inflating: data/normal/67.jpg      \n",
            "  inflating: data/normal/68.jpg      \n",
            "  inflating: data/normal/69.jpg      \n",
            "  inflating: data/normal/7.jpg       \n",
            "  inflating: data/normal/70.jpg      \n",
            "  inflating: data/normal/71.jpg      \n",
            "  inflating: data/normal/72.jpg      \n",
            "  inflating: data/normal/73.jpg      \n",
            "  inflating: data/normal/74.jpg      \n",
            "  inflating: data/normal/75.jpg      \n",
            "  inflating: data/normal/76.jpg      \n",
            "  inflating: data/normal/77.jpg      \n",
            "  inflating: data/normal/78.jpg      \n",
            "  inflating: data/normal/79.jpg      \n",
            "  inflating: data/normal/8.jpg       \n",
            "  inflating: data/normal/80.jpg      \n",
            "  inflating: data/normal/81.jpg      \n",
            "  inflating: data/normal/82.jpg      \n",
            "  inflating: data/normal/83.jpg      \n",
            "  inflating: data/normal/84.jpg      \n",
            "  inflating: data/normal/85.jpg      \n",
            "  inflating: data/normal/86.jpg      \n",
            "  inflating: data/normal/87.jpg      \n",
            "  inflating: data/normal/88.jpg      \n",
            "  inflating: data/normal/89.jpg      \n",
            "  inflating: data/normal/9.jpg       \n",
            "  inflating: data/normal/90.jpg      \n",
            "  inflating: data/normal/91.jpg      \n",
            "  inflating: data/normal/92.jpg      \n",
            "  inflating: data/normal/93.jpg      \n",
            "  inflating: data/normal/94.jpg      \n",
            "  inflating: data/normal/95.jpg      \n",
            "  inflating: data/normal/96.jpg      \n",
            "  inflating: data/normal/97.jpg      \n",
            "  inflating: data/normal/98.jpg      \n",
            "  inflating: data/normal/99.jpg      \n",
            "   creating: data/phishing/\n",
            "  inflating: data/phishing/000081.jpg  \n",
            "  inflating: data/phishing/000090.jpg  \n",
            "  inflating: data/phishing/000093.jpg  \n",
            "  inflating: data/phishing/000121.jpg  \n",
            "  inflating: data/phishing/000126.jpg  \n",
            "  inflating: data/phishing/000127.jpg  \n",
            "  inflating: data/phishing/1.jpg     \n",
            "  inflating: data/phishing/10.jpg    \n",
            "  inflating: data/phishing/100.jpg   \n",
            "  inflating: data/phishing/101.jpg   \n",
            "  inflating: data/phishing/102.jpg   \n",
            "  inflating: data/phishing/103.jpg   \n",
            "  inflating: data/phishing/104.jpg   \n",
            "  inflating: data/phishing/105.jpg   \n",
            "  inflating: data/phishing/106.jpg   \n",
            " extracting: data/phishing/107.jpg   \n",
            "  inflating: data/phishing/108.jpg   \n",
            "  inflating: data/phishing/109.jpg   \n",
            "  inflating: data/phishing/11.jpg    \n",
            "  inflating: data/phishing/110.jpg   \n",
            "  inflating: data/phishing/111.jpg   \n",
            "  inflating: data/phishing/112.jpg   \n",
            "  inflating: data/phishing/113.jpg   \n",
            "  inflating: data/phishing/114.jpg   \n",
            "  inflating: data/phishing/115.jpg   \n",
            "  inflating: data/phishing/116.jpg   \n",
            "  inflating: data/phishing/117.jpg   \n",
            "  inflating: data/phishing/118.jpg   \n",
            "  inflating: data/phishing/119.jpg   \n",
            "  inflating: data/phishing/12.jpg    \n",
            "  inflating: data/phishing/120.jpg   \n",
            "  inflating: data/phishing/121.jpg   \n",
            "  inflating: data/phishing/122.jpg   \n",
            "  inflating: data/phishing/123.jpg   \n",
            " extracting: data/phishing/124.jpg   \n",
            "  inflating: data/phishing/125.jpg   \n",
            "  inflating: data/phishing/126.jpg   \n",
            "  inflating: data/phishing/127.jpg   \n",
            "  inflating: data/phishing/128.jpg   \n",
            "  inflating: data/phishing/129.jpg   \n",
            "  inflating: data/phishing/13.jpg    \n",
            "  inflating: data/phishing/130.jpg   \n",
            "  inflating: data/phishing/131.jpg   \n",
            " extracting: data/phishing/132.jpg   \n",
            "  inflating: data/phishing/133.jpg   \n",
            "  inflating: data/phishing/134.jpg   \n",
            "  inflating: data/phishing/135.jpg   \n",
            "  inflating: data/phishing/14.jpg    \n",
            "  inflating: data/phishing/15.jpg    \n",
            "  inflating: data/phishing/16.jpg    \n",
            "  inflating: data/phishing/17.jpg    \n",
            "  inflating: data/phishing/18.jpg    \n",
            "  inflating: data/phishing/19.jpg    \n",
            "  inflating: data/phishing/2.jpg     \n",
            "  inflating: data/phishing/20.jpg    \n",
            "  inflating: data/phishing/21.jpg    \n",
            "  inflating: data/phishing/22.jpg    \n",
            "  inflating: data/phishing/23.jpg    \n",
            "  inflating: data/phishing/24.jpg    \n",
            "  inflating: data/phishing/25.jpg    \n",
            "  inflating: data/phishing/26.jpg    \n",
            "  inflating: data/phishing/27.jpg    \n",
            "  inflating: data/phishing/28.jpg    \n",
            "  inflating: data/phishing/29.jpg    \n",
            "  inflating: data/phishing/3.jpg     \n",
            "  inflating: data/phishing/30.jpg    \n",
            "  inflating: data/phishing/31.jpg    \n",
            "  inflating: data/phishing/32.jpg    \n",
            "  inflating: data/phishing/33.jpg    \n",
            "  inflating: data/phishing/34.jpg    \n",
            "  inflating: data/phishing/35.jpg    \n",
            "  inflating: data/phishing/36.jpg    \n",
            "  inflating: data/phishing/37.jpg    \n",
            "  inflating: data/phishing/38.jpg    \n",
            "  inflating: data/phishing/39.jpg    \n",
            "  inflating: data/phishing/4.jpg     \n",
            "  inflating: data/phishing/40.jpg    \n",
            "  inflating: data/phishing/41.jpg    \n",
            "  inflating: data/phishing/42.jpg    \n",
            "  inflating: data/phishing/43.jpg    \n",
            "  inflating: data/phishing/44.jpg    \n",
            "  inflating: data/phishing/45.jpg    \n",
            "  inflating: data/phishing/46.jpg    \n",
            "  inflating: data/phishing/47.jpg    \n",
            "  inflating: data/phishing/48.jpg    \n",
            "  inflating: data/phishing/49.jpg    \n",
            "  inflating: data/phishing/5.jpg     \n",
            "  inflating: data/phishing/50.jpg    \n",
            "  inflating: data/phishing/51.jpg    \n",
            "  inflating: data/phishing/52.jpg    \n",
            "  inflating: data/phishing/53.jpg    \n",
            "  inflating: data/phishing/54.jpg    \n",
            "  inflating: data/phishing/55.jpg    \n",
            "  inflating: data/phishing/56.jpg    \n",
            "  inflating: data/phishing/57.jpg    \n",
            "  inflating: data/phishing/58.jpg    \n",
            "  inflating: data/phishing/59.jpg    \n",
            "  inflating: data/phishing/6.jpg     \n",
            "  inflating: data/phishing/60.jpg    \n",
            "  inflating: data/phishing/61.jpg    \n",
            "  inflating: data/phishing/62.jpg    \n",
            "  inflating: data/phishing/63.jpg    \n",
            "  inflating: data/phishing/64.jpg    \n",
            "  inflating: data/phishing/65.jpg    \n",
            "  inflating: data/phishing/66.jpg    \n",
            "  inflating: data/phishing/67.jpg    \n",
            "  inflating: data/phishing/68.jpg    \n",
            "  inflating: data/phishing/69.jpg    \n",
            "  inflating: data/phishing/7.jpg     \n",
            " extracting: data/phishing/70.jpg    \n",
            "  inflating: data/phishing/71.jpg    \n",
            "  inflating: data/phishing/72.jpg    \n",
            " extracting: data/phishing/73.jpg    \n",
            "  inflating: data/phishing/74.jpg    \n",
            "  inflating: data/phishing/75.jpg    \n",
            "  inflating: data/phishing/77.jpg    \n",
            " extracting: data/phishing/78.jpg    \n",
            " extracting: data/phishing/79.jpg    \n",
            "  inflating: data/phishing/8.jpg     \n",
            " extracting: data/phishing/80.jpg    \n",
            "  inflating: data/phishing/81.jpg    \n",
            "  inflating: data/phishing/82.jpg    \n",
            "  inflating: data/phishing/83.jpg    \n",
            "  inflating: data/phishing/84.jpg    \n",
            "  inflating: data/phishing/85.jpg    \n",
            "  inflating: data/phishing/86.jpg    \n",
            "  inflating: data/phishing/87.jpg    \n",
            "  inflating: data/phishing/88.jpg    \n",
            "  inflating: data/phishing/89.jpg    \n",
            "  inflating: data/phishing/9.jpg     \n",
            "  inflating: data/phishing/90.jpg    \n",
            "  inflating: data/phishing/91.jpg    \n",
            "  inflating: data/phishing/92.jpg    \n",
            "  inflating: data/phishing/93.jpg    \n",
            "  inflating: data/phishing/94.jpg    \n",
            " extracting: data/phishing/95.jpg    \n",
            " extracting: data/phishing/96.jpg    \n",
            "  inflating: data/phishing/97.jpg    \n",
            "  inflating: data/phishing/98.jpg    \n",
            "  inflating: data/phishing/99.jpg    \n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  data.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7LYTT7koJztQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Бейзлайн - efficientnet_v2_s"
      ],
      "metadata": {
        "id": "ULw3R5QZSOza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3STSGe4GR_h_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.images, self.labels = [], []\n",
        "        for dirpath, _, filenames in os.walk(dataset_dir):\n",
        "            for filename in filenames:\n",
        "                label = 0 if 'normal' in dirpath else 1\n",
        "                img_path = os.path.join(dirpath, filename)\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageDataset(\"/content/data\", transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "7b60DPGFKB1w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_light_efficientnet():\n",
        "    model = models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
        "    for layer in model.features:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            layer.out_channels = max(16, layer.out_channels // 2)\n",
        "\n",
        "    num_ftrs = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dtIMhfR6KaG6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs=10):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct = 0.0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        epoch_acc = correct / train_size\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/train_size:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "    return model, best_acc"
      ],
      "metadata": {
        "id": "xtF2Gs-LKjtO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "vo5X0Nj9Klv6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp.pth\")\n",
        "    size_mb = os.path.getsize(\"temp.pth\") / (1024 * 1024)\n",
        "    os.remove(\"temp.pth\")\n",
        "    return size_mb"
      ],
      "metadata": {
        "id": "30BF81eBKn1k"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "light_efficientnet = create_light_efficientnet()\n",
        "light_efficientnet, acc_effnet = train_model(light_efficientnet, num_epochs=10)\n",
        "size_effnet = model_size(light_efficientnet)\n",
        "test_acc_effnet = evaluate_model(light_efficientnet)\n",
        "\n",
        "print(f\"Light EfficientNetV2 - Точность: {test_acc_effnet:.4f}, Размер: {size_effnet:.2f} MB\")"
      ],
      "metadata": {
        "id": "o75LFmwtKU5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c73d9d6-0680-460b-a9d1-0d9029b8c412"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 92.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3944, Accuracy: 0.8245\n",
            "Epoch 2, Loss: 0.2199, Accuracy: 0.9415\n",
            "Epoch 3, Loss: 0.0739, Accuracy: 0.9681\n",
            "Epoch 4, Loss: 0.0907, Accuracy: 0.9787\n",
            "Epoch 5, Loss: 0.0873, Accuracy: 0.9840\n",
            "Epoch 6, Loss: 0.0264, Accuracy: 1.0000\n",
            "Epoch 7, Loss: 0.0070, Accuracy: 1.0000\n",
            "Epoch 8, Loss: 0.0245, Accuracy: 0.9894\n",
            "Epoch 9, Loss: 0.0698, Accuracy: 0.9734\n",
            "Epoch 10, Loss: 0.0060, Accuracy: 1.0000\n",
            "Light EfficientNetV2 - Точность: 0.9375, Размер: 77.79 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Легкая модель"
      ],
      "metadata": {
        "id": "Xyx5CshuSida"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "SSf0k0DAK5_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "OvwT53fLLd7w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "flxF4dPkigdE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "c6o--C_INNzS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs=20):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct = 0.0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        epoch_acc = correct / train_size\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/train_size:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "    return model, best_acc"
      ],
      "metadata": {
        "id": "TJcKFkt7NLxn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_cnn = CustomCNN()\n",
        "custom_cnn, acc_custom = train_model(custom_cnn, num_epochs=20)\n",
        "size_custom = model_size(custom_cnn)\n",
        "test_acc_custom = evaluate_model(custom_cnn)\n",
        "\n",
        "print(f\"Custom CNN - Точность: {test_acc_custom:.4f}, Размер: {size_custom:.2f} MB\")"
      ],
      "metadata": {
        "id": "WNeF95OHNAnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f1700d-cd8a-4fde-ec96-560c7295694a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4739, Accuracy: 0.7872\n",
            "Epoch 2, Loss: 0.3259, Accuracy: 0.8564\n",
            "Epoch 3, Loss: 0.3312, Accuracy: 0.8617\n",
            "Epoch 4, Loss: 0.3413, Accuracy: 0.8670\n",
            "Epoch 5, Loss: 0.3669, Accuracy: 0.8777\n",
            "Epoch 6, Loss: 0.2622, Accuracy: 0.9043\n",
            "Epoch 7, Loss: 0.3093, Accuracy: 0.8989\n",
            "Epoch 8, Loss: 0.2630, Accuracy: 0.9043\n",
            "Epoch 9, Loss: 0.4136, Accuracy: 0.8351\n",
            "Epoch 10, Loss: 0.2867, Accuracy: 0.9096\n",
            "Epoch 11, Loss: 0.3238, Accuracy: 0.8936\n",
            "Epoch 12, Loss: 0.2672, Accuracy: 0.8936\n",
            "Epoch 13, Loss: 0.2535, Accuracy: 0.9255\n",
            "Epoch 14, Loss: 0.2631, Accuracy: 0.8883\n",
            "Epoch 15, Loss: 0.3401, Accuracy: 0.8936\n",
            "Epoch 16, Loss: 0.2625, Accuracy: 0.9096\n",
            "Epoch 17, Loss: 0.2227, Accuracy: 0.9149\n",
            "Epoch 18, Loss: 0.2205, Accuracy: 0.9202\n",
            "Epoch 19, Loss: 0.2210, Accuracy: 0.9202\n",
            "Epoch 20, Loss: 0.2293, Accuracy: 0.9043\n",
            "Custom CNN - Точность: 0.7917, Размер: 3.88 MB\n"
          ]
        }
      ]
    }
  ]
}